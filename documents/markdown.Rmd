---
title: "PSY6422 Data Management and Visualisation"
date: "2023-05-11"
output: pdf_document
---

#Why are we interested in travel?

The aim of this project is to better understand whether there were any changes in the destinations people were travelling from the United Kingdom (UK) to over time. This was chosen because over the past 10 years there have been a number of events in the UK that are likely to have influenced destination choice. Examples include: austerity measures, the UK exiting the European Union and the Coronavirus pandemic.

##Key research question

**Has travel from the UK changed over time?**

#What is the data source for this project?

The data was provided by the UK's Office for National Statistics and accessed in May 2023 at their [Travel Trends Dataset Pages](https://www.ons.gov.uk/peoplepopulationandcommunity/leisureandtourism/datasets/ukresidentsvisitsabroad). The specific files used were: \* 2017 to 2021 edition of the data set and \* 2009 to 2019 edition of the data set.

I have used the "Number of visits to specified countries: by main country visited and nationality 2017 to 2021" as this allowed a more nuanced view of travel which a region level may not pick up.

##How was the data collected?

This data provides estimated visits based on the International Passenger Survey (IPS). This survey uses interviews at all major airports, sea routes and Eurostar/ Eurotunnel terminals with approximately 250,000 people (although up to 800,000 interviews take place). However in 2021 the numbers takling part in the IPS were much lower. There is no further information on the sampling methods however at the scale and coverage these are trustworthy estimates. Additionally no other data sources exist at this level of detail.

A new method for calculating the 2021 estimates were introduced which superceeds previous years. The estimates that overlap are the same in the 2009 to 2019 datasets so I have continued with the merge but this should be noted.

##Is there anything that may impact the visualisation?

The data for 2021 is more limited than previous years of the IPS. The smaller number of travellers and issues collecting the data at key terminals led to an overall smaller sample of passengers in the IPS. This means that there is more error in the estimation than other years (excluding 2020 where no country level data is available). Countries are consistent every year but if this changes then some of the data importing and colours will need changed.

##Codebook

A full codebook describing the variables from the original dataset and any calculated values are available [Link](git%20hub%20page%20KE). The variables taken from the raw data that were not removed are: 
```{r, echo=FALSE }

table <- data.frame (variable  = c("country", "2009...2021 (each years individual variable)"), 
                     description = c("main destination travelled to from the UK ", "number of visits in thousands (000s)"),
                     other_notes = c("Source ONS raw data apart from the dfColour","Apart from dfv2 where years correspond to ranks"))


knitr::kable (table)
```


#How was the data prepared for visualisation?

##Libraries and RENV

The following packages were used in this project:

```{r, message=FALSE, warning=FALSE, results="hide"}

renv::restore()
#Libraries
library(here)#Here for loading in the data
library(tidyverse)#Tidyverse for data management
library(ggplot2) #chart making
library(readxl)#Reading in Excel sheets as that is how the data is stored 
library(plotly)#Making scroll over charts
library(htmlwidgets)#To save interactive chart
```

To support future replication the this R Project used RENV (version:0.17.3) with package versions available in the following file [link](ADDINGITHUB)

##Importing the data

###Cleaning variables

As an initial step I created a set of values that supported the importation and data cleaning processes. In theory these will allow for a more recent dataset to also be used by changing the input file and changing the years that we are keeping.

```{r}
# 2. Load the data in

#Variables required for data cleaning of the ONS files

ONSList <- 68 #The length of the ONS data table, these are consistent

yearsdf1721 <- c("2017","2018","2019",
                 "2020","2021") # These are the years that we will want to take from this data frame

yearsdf0919 <- c("2009","2010","2011",
                 "2012","2013","2014",
                 "2015","2016") #Years wanted, always choose most recent

summaries <- list('Total World',
                  'Other Countries',"Europe",
                  '- of which EU',
                  '- of which EU Oth',
                  '- of which EU15',
                  "North America") #summary values used in the dataset

# Raw data locations
data1721 = (here("raw_data","section3ukresidentsvisitsabroad2017to2021.xlsx")) #data for 2017 to 2021
data0919 = (here ("raw_data","section3ukresidentsvisitsabroad2009to2019.xlsx")) #data for 2009 to 2017
```

###Importing the data

The following code imports the data into R. It then renames the columns to match those in the original ONS data file and removes the rows that are blank.

```{r, results="hide", message= FALSE, error=FALSE, warning=FALSE}
# Load in latest dataset 2017-2021            
df1721<- read_excel(data1721,
                    sheet="3.06", 
                    skip=10,
                    n_max=ONSList)

##rename columns 2017-2021
df1721_n <- tibble(x = 1:9, y = c("country", "coltoremove", "2017","2018",
                                  "2019","2020","2021","blankroremove",
                                  "avgrowth1519"))#list of column names

names(df1721) <- df1721_n %>% select(y) %>% pull()#function to change the names 

##Remove NAs in rows and select years only 2017 to 2021
df1721 <- df1721 %>% 
          select("country",all_of(yearsdf1721)) %>% #Select correct years
          drop_na("country")# remove blank rows

## Read the excel file for 2009 to 2019
df0919 <- read_excel(data0919,
                     sheet="3.10", 
                     skip=10,
                     n_max=ONSList)

###rename columns 2009 - 2019
df0919_n <- tibble(x=1:19, y= c("country", 
                                "coltoremove",
                                "2009","2010","2011",
                                "2012","2013","2014",
                                "2015","2016","2017",
                                "2018","2019",
                                "blank1",
                                "change1819",
                                "blank2",
                                "growth1819",
                                "blank3",
                                "Avgrowth1519"))#list of column names

names(df0919) <- df0919_n %>% select(y) %>% pull() #function to change the names 

###Remove NAs in rows and select years only to 2017
df0919 <- df0919 %>% 
          select("country",all_of(yearsdf0919)) %>% #Select correct years
          drop_na("country")# remove blank rows
```

###Merge the files Once both data sets were in the same shape so that I could then merge into a data set that has all available years. I then removed the summary variables.

```{r, results="hide", message= FALSE, error=FALSE, warning=FALSE}
#Merge the datasets
df0921 <- left_join(df0919, df1721,by="country")

##Remove summaries in the dataset
df0921 <-df0921 %>% 
         filter((!country %in% summaries)) 

```

###Use of ranks As 58 countries is tricky to visualise I decided to choose a suitable cut off based on ranks for the visualisation. These were added here using the following code.I decided on 2021 to be the key year for this cut off because it is the most recent and presents a "now" vs the "past" view that is more intuitive.

## Add ranking variable for 2021 (this will be used to decide on the cases kept)

```{r, results="hide", message= FALSE, error=FALSE, warning=FALSE}
## Add ranking variable for 2021 (this will be used to decide on the cases kept)
df0921 <- df0921 %>% 
           mutate(rank_cut = rank(-`2021`, ties.method = "average"))

#save combined data set
comData_n = paste(here("created_data"), "/travel0921.csv", sep = "")   
write.csv(df0921, comData_n)   #Write data to CSV

```

```{r}
#check data
head(df0921)
```

#Visualising the data 

After reviewing the data it was clear that there were some countries with very high number of visits and most that were much lower. This made a line plot difficult to interpret and didn't show if there were any overall trends of interest - the message was lost in noise. To account for this I decided to use just 2009 and 2021 in my visualisations as they are the earliest and latest date available. Additionally any visualisation would be a subset of the countries as 58 because that many countries made it hard to interpret and pick out countries of interest. 


##Visualisation 1

With visualisation 1 I wanted to use the raw number of visits to show the change in travel. I decided on a dumbell plot because I felt that it showed the difference between both 2009 and 2021 and the countries well. It is less cluttered than a traditional clustered bar chart which can prevent interpretation. 


### How was this created?

Initially I created variables to select the years and the number of countries I wanted included. This was to allow for any quick changes based on how the final graph was looking. After this the data was then moved into a long format with the year column name becoming the year variable. The number of visits for each year is included as visits.  

```{r}
#3.1. Create variables to allow us to choose the number of 2021 ranks 

cutrank1 <- 20 #number of countries that we want included in the chart
yrs_inc1 <- c(2009, 2021) # years that we want to include (can be any year from 2009-2021 apart from 2020)

#3.2 Create summary DF based on the number of countries

dfv1 <- df0921 %>% 
        filter (rank_cut<=cutrank1)

#3.3. Convert to long format

longdfv1 <- dfv1 %>% select("country", 
                            "2009", "2010", 
                            "2011", "2012", 
                            "2013", "2014", 
                            "2015", "2016", 
                            "2017", "2018",
                            "2019", "2021") %>% #2020 dropped due to no data 
                      pivot_longer(!country, 
                                   names_to = "year", 
                                   names_transform = list(year = as.factor), #Changed to factor to allow for it to be treated as a category
                                   values_to = "visits") %>%
                      arrange(desc(visits)) %>% #order by the most visited to the least
                      filter(year %in% yrs_inc1) #removes years that we are not interested in as defined above

head(longdfv1)
```

###Visualisation 
To create the dumbell plot I added the visits data to geom_point and then added a line to connect the 2 dates together. As some data points overlap I ensured that these points were opaque. Additionally I created a dynamic subtitle in case the years chosen changes in the future (e.g. if we decide that the 2019 pre-covid year is a more appropriate comparison). I kept the colours as default as I felt that they actually worked quite well. The countries were reordered by the largest visits but as you can see this had mixed results. 

```{r}
#3.4. Create a dumbbell plot 

#3.4.1. Create a subtitle that changes with the data selected. 
subtitle1 <- paste("Showing the top", toString(cutrank1), "most visited countries in 2021")

#3.4.2. Match the aesthetics (basic plot)

p1 <- ggplot(longdfv1, 
            aes(x = visits, y = reorder(country, visits)))

#3.4.3. Add layers 
v1 <- p1 +   #lines to show the years are connected 
             geom_line(color="grey") + 
             #shows the year
             geom_point(aes(color = year), size = 3, alpha=0.8) +  
             #Legend at the bottom for ease
             theme(legend.position = "bottom") + 
             #Labels for the chart
             labs(x = "Number of visits from the UK (000s)", 
                  y = "Country", 
                  title = "Number of visits abroad from the UK in 2009 and 2021 by main country visited",
                  subtitle = subtitle1,
                  caption= "Source: Office for National Statistics International Passenger Survey") 

#Display visualisation 1             
v1
```


#What data are we using for this project? ##About the IPS ##Raw data source ##Aditional data created #How was the data prepared? Explain that due to the repeating nature hoped to make a set of code that could add in the ##Packages and RENV Include a table of versions ##Removing additional information from the Excel sheets ##Merge the data ##Creating a ranking variable

#What would you have done differently?

An extension with many more years of data would be to create a dashboard of this information. Individuals are likely to be interested in countries that they have an affinity for so it would be good for people to have this option. An example of this has been completed by the ONS using ranks and I think it could work for travel [link](ONS)
